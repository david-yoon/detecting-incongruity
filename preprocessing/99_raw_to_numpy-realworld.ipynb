{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import cPickle as pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from file_util import create_folder\n",
    "maxInt = sys.maxsize\n",
    "decrement = True\n",
    "\n",
    "while decrement:\n",
    "    # decrease the maxInt value by factor 10\n",
    "    # as long as the OverflowError occurs.\n",
    "    \n",
    "    decrement = False\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "        decrement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_dataset        = 'real_world_articles/old'\n",
    "name_dataset        = 'real_world_articles/new'\n",
    "path_raw_data       = '../data/raw/' + name_dataset + '/'\n",
    "path_processed_data = '../data/' + name_dataset + '/whole/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder(path_raw_data)\n",
    "# create_folder(path_processed_data + '/train')\n",
    "# create_folder(path_processed_data + '/dev')\n",
    "create_folder(path_processed_data + '/test')\n",
    "# create_folder(path_processed_data + '/debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read voca from dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196779"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dic = '../data/news-19_paragraph_swap-random-1m/whole/dic_mincutN.txt'\n",
    "\n",
    "list_voca = []\n",
    "with open(target_dic, 'r') as f:\n",
    "    list_voca = f.readlines()\n",
    "    list_voca = [x.strip() for x in list_voca]\n",
    "\n",
    "dic_voca = {}\n",
    "for voca in list_voca:\n",
    "    dic_voca[voca] = len(dic_voca)\n",
    "\n",
    "len(dic_voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "dic_voca_lower = copy.deepcopy(dic_voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_voca_lower['<eos>'] = dic_voca_lower['<EOS>']\n",
    "dic_voca_lower['<eop>'] = dic_voca_lower['<EOP>']\n",
    "\n",
    "del dic_voca_lower['<EOS>']\n",
    "del dic_voca_lower['<EOP>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196779"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic_voca_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dic_voca_lower[''], dic_voca_lower['<UNK>'], dic_voca_lower['<eos>'], dic_voca_lower['<eop>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "data= []\n",
    "with open(path_raw_data + 'test.tsv', 'r') as f:\n",
    "    data_csv = csv.reader(f, delimiter='\\t',\n",
    "                          quoting=csv.QUOTE_NONE)\n",
    "    for row in data_csv:\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(data):\n",
    "    print(\"mean\", np.average(data))\n",
    "    print(\"std\", np.std(data))\n",
    "    print(\"max\", np.max(data))\n",
    "    print(\"95.xx coverage\", np.average(data) +  2*np.std(data) )\n",
    "    print(\"99.73 coverage\", np.average(data) +  3*np.std(data) )\n",
    "    print(\"99.95 coverage\", np.average(data) +  3.5*np.std(data) )\n",
    "    print(\"99.99 coverage\", np.average(data) +  4*np.std(data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_len\n",
      "('mean', 11.237227486953639)\n",
      "('std', 3.541768671679837)\n",
      "('max', 38)\n",
      "('95.xx coverage', 18.320764830313312)\n",
      "('99.73 coverage', 21.86253350199315)\n",
      "('99.95 coverage', 23.63341783783307)\n",
      "('99.99 coverage', 25.40430217367299)\n"
     ]
    }
   ],
   "source": [
    "head = [x[1].strip() for x in data]\n",
    "head_len = [len(x.split()) for x in head]\n",
    "print('head_len')\n",
    "print_info(head_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_len\n",
      "('mean', 752.7194849987923)\n",
      "('std', 392.8987616809875)\n",
      "('max', 6306)\n",
      "('95.xx coverage', 1538.5170083607672)\n",
      "('99.73 coverage', 1931.4157700417547)\n",
      "('99.95 coverage', 2127.8651508822486)\n",
      "('99.99 coverage', 2324.3145317227422)\n"
     ]
    }
   ],
   "source": [
    "body = [x[2].strip() for x in data]\n",
    "body_len = [len(x.split()) for x in body ]\n",
    "print('body_len')\n",
    "print_info(body_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_len\n",
      "('mean', 26.560091900302776)\n",
      "('std', 12.933705983369837)\n",
      "('max', 51)\n",
      "('95.xx coverage', 52.42750386704245)\n",
      "('99.73 coverage', 65.3612098504123)\n",
      "('99.95 coverage', 71.82806284209721)\n",
      "('99.99 coverage', 78.29491583378213)\n"
     ]
    }
   ],
   "source": [
    "context_len = [len(x.split('<EOP>')) for x in body]\n",
    "print('context_len')\n",
    "print_info(context_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_sentence\n",
      "('mean', 27.37789446768443)\n",
      "('std', 18.148781561876078)\n",
      "('max', 1578)\n",
      "('95.xx coverage', 63.67545759143658)\n",
      "('99.73 coverage', 81.82423915331266)\n",
      "('99.95 coverage', 90.8986299342507)\n",
      "('99.99 coverage', 99.97302071518874)\n"
     ]
    }
   ],
   "source": [
    "body_sentence = []\n",
    "for sent in body:\n",
    "    sent = sent.split('<EOP>')\n",
    "    body_sentence.extend(sent)\n",
    "body_len = [ len(x.split()) for x in body_sentence ]    \n",
    "print('body_sentence')\n",
    "print_info(body_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# encode to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_length(data, max_len_t, max_len_b):\n",
    "    data_t, data_b = data\n",
    "    \n",
    "    list_zeros = np.zeros(max_len_b, 'int32').tolist()\n",
    "    fl_data_t = []\n",
    "    for datum in data_t:\n",
    "        try:\n",
    "            datum = list(datum)\n",
    "        except:\n",
    "            pass\n",
    "        _len = len(datum)\n",
    "        if _len >= max_len_t:\n",
    "            fl_data_t.append( datum[:max_len_t] )\n",
    "        else:\n",
    "            fl_data_t.append( datum + list_zeros[:(max_len_t-_len)] )\n",
    "            \n",
    "    fl_data_b = []\n",
    "    for datum in data_b:\n",
    "        try:\n",
    "            datum = list(datum)\n",
    "        except:\n",
    "            pass\n",
    "        _len = len(datum)\n",
    "        if _len >= max_len_b:\n",
    "            fl_data_b.append( datum[:max_len_b] )\n",
    "        else:\n",
    "            fl_data_b.append( datum + list_zeros[:(max_len_b-_len)] )\n",
    "    \n",
    "    np_data_t = np.asarray(fl_data_t, dtype='int32')\n",
    "    np_data_b = np.asarray(fl_data_b, dtype='int32')\n",
    "    \n",
    "    data = [np_data_t, np_data_b]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-24T09:41:26.397402\n",
      "10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 178019 Done\n",
      "2020-05-24T09:42:03.056171\n"
     ]
    }
   ],
   "source": [
    "csv_reader = csv.reader(open(path_raw_data + 'test.tsv', 'r'),\n",
    "                        delimiter='\\t',\n",
    "                        quoting=csv.QUOTE_NONE)\n",
    "\n",
    "print datetime.datetime.now().isoformat()\n",
    "ids = []\n",
    "heads = []\n",
    "bodys = []\n",
    "labels = []\n",
    "for n, row in enumerate(csv_reader):\n",
    "    \n",
    "#     if n <  3000000:\n",
    "#         continue\n",
    "\n",
    "#     if n >=  3000000:\n",
    "#         continue\n",
    "        \n",
    "                \n",
    "    if (n+1) % 10000 == 0: print n+1,\n",
    "    \n",
    "    ids.append(row[0])\n",
    "    labels.append(0)\n",
    "    \n",
    "    head = []\n",
    "    for tkn in row[1].lower().strip().split():\n",
    "        if tkn in dic_voca_lower:\n",
    "            head.append(dic_voca_lower[tkn])\n",
    "        else:\n",
    "            head.append(1)\n",
    "            \n",
    "    heads.append(head)\n",
    "    \n",
    "    body = []\n",
    "    for tkn in row[2].lower().strip().split():\n",
    "        if tkn in dic_voca_lower:\n",
    "            body.append(dic_voca_lower[tkn])\n",
    "        else:\n",
    "            body.append(1)\n",
    "            \n",
    "    bodys.append(body)\n",
    "    \n",
    "print n+1, 'Done'\n",
    "print datetime.datetime.now().isoformat() # ~5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-24T09:42:03.064060\n",
      "2020-05-24T09:42:28.684434\n"
     ]
    }
   ],
   "source": [
    "print datetime.datetime.now().isoformat()\n",
    "[np_heads, np_bodys] = fit_length([heads, bodys], 25, 2100)\n",
    "print datetime.datetime.now().isoformat() # ~3 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-24T09:42:28.694558\n",
      "2020-05-24T09:42:29.311515\n"
     ]
    }
   ],
   "source": [
    "print datetime.datetime.now().isoformat()\n",
    "t_trainpath = path_processed_data + '/test/test_title.npy'\n",
    "np.save(t_trainpath, np_heads)\n",
    "b_trainpath = path_processed_data + '/test/test_body.npy'\n",
    "np.save(b_trainpath, np_bodys)\n",
    "l_trainpath = path_processed_data + '/test/test_label.npy'\n",
    "np.save(l_trainpath, labels)\n",
    "print datetime.datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178019,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/real_world_articles/new/whole/test/test_label.npy', 'r') as f:\n",
    "    tt = np.load(f)\n",
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf114_p27]",
   "language": "python",
   "name": "conda-env-tf114_p27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
