{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# import cPickle as pickle\n",
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "maxInt = sys.maxsize\n",
    "decrement = True\n",
    "\n",
    "while decrement:\n",
    "    # decrease the maxInt value by factor 10\n",
    "    # as long as the OverflowError occurs.\n",
    "    \n",
    "    decrement = False\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "        decrement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_voca = ''\n",
    "# with open('../data/nela-18/whole/dic_mincutN.pkl', 'rb') as f:\n",
    "#     dic_voca = pickle.load(f)\n",
    "\n",
    "dic_voca = ''\n",
    "with open('../data/nela-18-past-method/whole/dic_mincutN.pkl', 'rb') as f:\n",
    "    dic_voca = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "dic_voca_lower = copy.deepcopy(dic_voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_voca_lower['<eos>'] = dic_voca_lower['<EOS>']\n",
    "dic_voca_lower['<eop>'] = dic_voca_lower['<EOP>']\n",
    "\n",
    "del dic_voca_lower['<EOS>']\n",
    "del dic_voca_lower['<EOP>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic_voca_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3\n"
     ]
    }
   ],
   "source": [
    "print(dic_voca_lower[''], dic_voca_lower['<UNK>'], dic_voca_lower['<eos>'], dic_voca_lower['<eop>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import sys\n",
    "# import numpy as np\n",
    "\n",
    "# data= []\n",
    "# with open('../data/raw/real_world_articles_ascii.tsv', 'r') as f:\n",
    "#     data_csv = csv.reader(f, delimiter='\\t')\n",
    "#     for row in data_csv:\n",
    "#         data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_info(data):\n",
    "#     print(\"mean\", np.average(data))\n",
    "#     print(\"std\", np.std(data))\n",
    "#     print(\"max\", np.max(data))\n",
    "#     print(\"95.xx coverage\", np.average(data) +  2*np.std(data) )\n",
    "#     print(\"99.73 coverage\", np.average(data) +  3*np.std(data) )\n",
    "#     print(\"99.95 coverage\", np.average(data) +  3.5*np.std(data) )\n",
    "#     print(\"99.99 coverage\", np.average(data) +  4*np.std(data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head = [x[1].strip() for x in data]\n",
    "# head_len = [len(x.split()) for x in head]\n",
    "# print('head_len')\n",
    "# print_info(head_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body = [x[2].strip() for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_len = [len(x.split()) for x in body ]\n",
    "# print('body_len')\n",
    "# print_info(body_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_len = [len(x.split('<EOP>')) for x in body]\n",
    "# print('context_len')\n",
    "# print_info(context_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_sentence = []\n",
    "# for sent in body:\n",
    "#     sent = sent.split('<EOP>')\n",
    "#     body_sentence.extend(sent)\n",
    "# body_len = [ len(x.split()) for x in body_sentence ]    \n",
    "# print('body_sentence')\n",
    "# print_info(body_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# encode to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_length(data, max_len_t, max_len_b):\n",
    "    data_t, data_b = data\n",
    "    \n",
    "    list_zeros = np.zeros(max_len_b, 'int32').tolist()\n",
    "    fl_data_t = []\n",
    "    for datum in data_t:\n",
    "        try:\n",
    "            datum = list(datum)\n",
    "        except:\n",
    "            pass\n",
    "        _len = len(datum)\n",
    "        if _len >= max_len_t:\n",
    "            fl_data_t.append( datum[:max_len_t] )\n",
    "        else:\n",
    "            fl_data_t.append( datum + list_zeros[:(max_len_t-_len)] )\n",
    "            \n",
    "    fl_data_b = []\n",
    "    for datum in data_b:\n",
    "        try:\n",
    "            datum = list(datum)\n",
    "        except:\n",
    "            pass\n",
    "        _len = len(datum)\n",
    "        if _len >= max_len_b:\n",
    "            fl_data_b.append( datum[:max_len_b] )\n",
    "        else:\n",
    "            fl_data_b.append( datum + list_zeros[:(max_len_b-_len)] )\n",
    "    \n",
    "    np_data_t = np.asarray(fl_data_t, dtype='int32')\n",
    "    np_data_b = np.asarray(fl_data_b, dtype='int32')\n",
    "    \n",
    "    data = [np_data_t, np_data_b]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05T10:13:24.369422\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "95069 Done\n",
      "2019-12-05T10:13:40.549447\n"
     ]
    }
   ],
   "source": [
    "csv_reader = csv.reader(open('../data/raw/real_world_articles_ascii.tsv', 'r'), delimiter='\\t')\n",
    "\n",
    "print (datetime.datetime.now().isoformat())\n",
    "ids = []\n",
    "heads = []\n",
    "bodys = []\n",
    "labels = []\n",
    "for n, row in enumerate(csv_reader):\n",
    "    if (n+1) % 10000 == 0: print (n+1),\n",
    "    \n",
    "    ids.append(row[0])\n",
    "    labels.append(int(row[3]))\n",
    "    \n",
    "    head = []\n",
    "    for tkn in row[1].lower().strip().split():\n",
    "        if tkn in dic_voca_lower:\n",
    "            head.append(dic_voca_lower[tkn])\n",
    "        else:\n",
    "            head.append(1)\n",
    "            \n",
    "    heads.append(head)\n",
    "    \n",
    "    body = []\n",
    "    for tkn in row[2].lower().strip().split():\n",
    "        if tkn in dic_voca_lower:\n",
    "            body.append(dic_voca_lower[tkn])\n",
    "        else:\n",
    "            body.append(1)\n",
    "            \n",
    "    bodys.append(body)\n",
    "    \n",
    "print (n+1, 'Done')\n",
    "print (datetime.datetime.now().isoformat()) # ~5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05T10:13:40.554698\n",
      "2019-12-05T10:14:02.634130\n"
     ]
    }
   ],
   "source": [
    "print (datetime.datetime.now().isoformat())\n",
    "[np_heads, np_bodys] = fit_length([heads, bodys], 25, 2800)\n",
    "print (datetime.datetime.now().isoformat()) # ~3 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05T10:14:32.151488\n",
      "2019-12-05T10:14:32.825417\n"
     ]
    }
   ],
   "source": [
    "print (datetime.datetime.now().isoformat())\n",
    "t_trainpath = '../data/nela-18-past-method/whole/test/test_title.npy'\n",
    "np.save(t_trainpath, np_heads)\n",
    "b_trainpath = '../data/nela-18-past-method/whole/test/test_body.npy'\n",
    "np.save(b_trainpath, np_bodys)\n",
    "l_trainpath = '../data/nela-18-past-method/whole/test/test_label.npy'\n",
    "np.save(l_trainpath, labels)\n",
    "print (datetime.datetime.now().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf114_p37]",
   "language": "python",
   "name": "conda-env-tf114_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
